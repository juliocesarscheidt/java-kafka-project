version: '3.4'

services:
  zookeeper:
    container_name: zookeeper
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:6.0.0
    restart: on-failure
    networks:
      - subnet_0
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data

  kafka:
    container_name: kafka
    hostname: kafka
    image: confluentinc/cp-kafka:6.0.0
    restart: on-failure
    networks:
      - subnet_0
    ports:
      - 9092:9092
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

  elastic:
    container_name: elastic
    hostname: elastic
    image: juliocesarmidia/elasticsearch:7.7.0
    build:
      context: ./elasticsearch
    restart: on-failure
    networks:
      - subnet_0
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
      bootstrap.memory_lock: "true"
      discovery.type: "single-node"
      node.name: "elastic"
      cluster.name: "elastic-cluster"
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    stop_grace_period: 10s
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:9200/_cluster/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  kafka-producer:
    container_name: kafka-producer
    build:
      context: ./producer
    restart: "no"
    networks:
      - subnet_0
    environment:
      JAVA_OPTIONS: -Xmx400m
      BOOTSTRAP_SERVERS: kafka:9092
      TOPIC_NAME: topic_0
      TWITTER_CONSUMER_KEY: ${TWITTER_CONSUMER_KEY}
      TWITTER_CONSUMER_SECRET: ${TWITTER_CONSUMER_SECRET}
      TWITTER_ACCESS_TOKEN: ${TWITTER_ACCESS_TOKEN}
      TWITTER_ACCESS_TOKEN_SECRET: ${TWITTER_ACCESS_TOKEN_SECRET}

  kafka-consumer:
    container_name: kafka-consumer
    build:
      context: ./consumer
    restart: on-failure
    networks:
      - subnet_0
    environment:
      JAVA_OPTIONS: -Xmx400m
      BOOTSTRAP_SERVERS: kafka:9092
      TOPIC_NAME: topic_0
      ELASTICSEARCH_HOST: elastic
      ELASTICSEARCH_PORT: 9200

networks:
  subnet_0:
    driver: bridge

volumes:
  zookeeper-data: {}
  elasticsearch-data: {}
